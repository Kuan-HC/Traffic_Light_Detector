{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import cv2\n",
    "\n",
    "from PIL import ImageDraw\n",
    "from PIL import ImageColor\n",
    "\n",
    "cmap = ImageColor.colormap\n",
    "print(\"Number of colors =\", len(cmap))\n",
    "COLOR_LIST = sorted([c for c in cmap.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TLClassifier(object):\n",
    "    def __init__(self):\n",
    "        #TODO load classifier\n",
    "        SSD_GRAPH_FILE = 'sfrozen_inference_graph.pb'\n",
    "        \n",
    "        #self.session = None\n",
    "        self.detection_graph = self.load_graph(SSD_GRAPH_FILE)\n",
    "    \n",
    "    def load_graph(self, graph_file):\n",
    "        \"\"\"Loads a frozen inference graph\"\"\"\n",
    "        graph = tf.Graph()\n",
    "        with graph.as_default():\n",
    "            od_graph_def = tf.GraphDef()\n",
    "            with tf.gfile.GFile(graph_file, 'rb') as fid:\n",
    "                serialized_graph = fid.read()\n",
    "                od_graph_def.ParseFromString(serialized_graph)\n",
    "                tf.import_graph_def(od_graph_def, name='')\n",
    "                \n",
    "        return graph\n",
    "    \n",
    "    def get_classification(self, image):\n",
    "        \"\"\"Determines the color of the traffic light in the image\n",
    "\n",
    "        Args:\n",
    "            image (cv::Mat): image containing the traffic light\n",
    "\n",
    "        Returns:\n",
    "            int: ID of traffic light color (specified in styx_msgs/TrafficLight)\n",
    "\n",
    "        \"\"\"\n",
    "        #TODO implement light color prediction\n",
    "        # The input placeholder for the image.\n",
    "        # `get_tensor_by_name` returns the Tensor with the associated name in the Graph.\n",
    "        image_tensor = self.detection_graph.get_tensor_by_name('image_tensor:0')\n",
    "\n",
    "        # Each box represents a part of the image where a particular object was detected.\n",
    "        detection_boxes = self.etection_graph.get_tensor_by_name('detection_boxes:0')\n",
    "\n",
    "        # Each score represent how level of confidence for each of the objects.\n",
    "        # Score is shown on the result image, together with the class label.\n",
    "        detection_scores = self.detection_graph.get_tensor_by_name('detection_scores:0')\n",
    "\n",
    "        # The classification of the object (integer id).\n",
    "        detection_classes = self.detection_graph.get_tensor_by_name('detection_classes:0')\n",
    "        \n",
    "        image = cv2.resize(image, (300, 300))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image_np = np.expand_dims(np.asarray(image, dtype=np.uint8), 0)\n",
    "        \n",
    "        with tf.Session(graph = self.detection_graph) as sess:                \n",
    "        # Actual detection.\n",
    "            (boxes, scores, classes) = sess.run([detection_boxes, detection_scores, detection_classes], \n",
    "                                        feed_dict={image_tensor: image_np})\n",
    "\n",
    "            # Remove unnecessary dimensions\n",
    "            boxes = np.squeeze(boxes)\n",
    "            scores = np.squeeze(scores)\n",
    "            classes = np.squeeze(classes)\n",
    "            \n",
    "            '''\n",
    "            Below if for debugging\n",
    "            '''            \n",
    "            confidence_cutoff = 0.8\n",
    "            # Filter boxes with a confidence score less than `confidence_cutoff`\n",
    "            boxes, scores, classes = self.filter_boxes(confidence_cutoff, boxes, scores, classes)\n",
    "            \n",
    "            # The current box coordinates are normalized to a range between 0 and 1.\n",
    "            # This converts the coordinates actual location on the image.\n",
    "            width, height = image.size\n",
    "            box_coords = self.to_image_coords(boxes, height, width)\n",
    "\n",
    "            # Each class with be represented by a differently colored box\n",
    "            self.draw_boxes(image, box_coords, classes)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(image)\n",
    "        \n",
    "        \n",
    "        return TrafficLight.UNKNOWN\n",
    "    \n",
    "    def filter_boxes(self, min_score, boxes, scores, classes):\n",
    "        \"\"\"Return boxes with a confidence >= `min_score`\"\"\"\n",
    "        n = len(classes)\n",
    "        idxs = []\n",
    "        for i in range(n):\n",
    "            if scores[i] >= min_score:\n",
    "                idxs.append(i)\n",
    "    \n",
    "        filtered_boxes = boxes[idxs, ...]\n",
    "        filtered_scores = scores[idxs, ...]\n",
    "        filtered_classes = classes[idxs, ...]\n",
    "        return filtered_boxes, filtered_scores, filtered_classes\n",
    "\n",
    "    def to_image_coords(self, boxes, height, width):\n",
    "        \"\"\"\n",
    "        The original box coordinate output is normalized, i.e [0, 1].\n",
    "    \n",
    "        This converts it back to the original coordinate based on the image\n",
    "        size.\n",
    "        \"\"\"\n",
    "        box_coords = np.zeros_like(boxes)\n",
    "        box_coords[:, 0] = boxes[:, 0] * height\n",
    "        box_coords[:, 1] = boxes[:, 1] * width\n",
    "        box_coords[:, 2] = boxes[:, 2] * height\n",
    "        box_coords[:, 3] = boxes[:, 3] * width\n",
    "    \n",
    "        return box_coords\n",
    "\n",
    "    def draw_boxes(self, image, boxes, classes, thickness=4):\n",
    "        \"\"\"Draw bounding boxes on the image\"\"\"\n",
    "        draw = ImageDraw.Draw(image)\n",
    "        for i in range(len(boxes)):\n",
    "            bot, left, top, right = boxes[i, ...]\n",
    "            class_id = int(classes[i])\n",
    "            color = COLOR_LIST[class_id]\n",
    "            draw.line([(left, top), (left, bot), (right, bot), (right, top), (left, top)], width=thickness, fill=color)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = TLClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
